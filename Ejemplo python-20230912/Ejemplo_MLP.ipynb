{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Implementación de un Modelo de Clasificación utilizando MLP**\n",
        "\n",
        "*John Atkinson*\n",
        "\n",
        "Este programa permite implementar una red neuronal multi-capa del tipo MLP (Multi-Layer Perceptron) para un problema de predicción simple. El modelo  aprende desde un conjunto de datos de entrenamiento (*training dataset*) y luego  prueba las predicciones sobre un conjunto de datos de prueba (*test dataset*).\n",
        "\n",
        "El problema se trata de predecir si es que un paciente cobrará seguros (1 o 0) dependiendo de sus condiciones de salud  (edad, sexo, indice de masa corporal-IMC, número de hijos, fumador, región, costos médicos -en dólares, y variable de predicción - SolicitaSeguro). Para esto se deberá cargar un dataset en excel con datos para el problema (\"*Seguros.xlsx*\").\n",
        "\n",
        "El método a utilizar es un clasificador binario (cobra -1- o no cobra -0- seguro) llamado **MLPClassifier** de la biblioteca de Machine Learning [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html).\n"
      ],
      "metadata": {
        "id": "tYgXuRu3_XsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero, importamos algunas librerías relevantes para graficar, cargar datos, y luego las necesarias de SKLEARN para entrenar y evaluar un clasificador perceptron multi-layer (MLP). Note que el método para entrenar un clasificador MLP se llama *MLPClassifier*:"
      ],
      "metadata": {
        "id": "K14qrIQfA9LJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "dvCQb85dO0mu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero, definimos la función **CargarDatos(..)** para cargar los datos desde un conjunto de datos (dataset) de entrenamiento de datos de seguros. Cada registro viene con las variables independientes y la variable dependiente de predicción (*SolicitaSeguro*) que se carga en un dataframe panda:"
      ],
      "metadata": {
        "id": "LIPJ9sRrCTEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CargarDatos():\n",
        "  df     = pd.read_excel('Seguros.xlsx')\n",
        "  data   = df.drop(['SolicitaSeguro'],axis=1)\n",
        "  labels = df.SolicitaSeguro\n",
        "  return(data,labels)"
      ],
      "metadata": {
        "id": "LoxoXf9-Q5sq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comenzamos el programa principal, cargando nuestros datos:"
      ],
      "metadata": {
        "id": "_mhGpA1OTRWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data, labels = CargarDatos()"
      ],
      "metadata": {
        "id": "INqu_j16ZJAP"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora separamos los datos al azar en un dataset  de entrenamiento (70%) y otro de prueba (30%):"
      ],
      "metadata": {
        "id": "uNNhIlXwT4sD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.3)"
      ],
      "metadata": {
        "id": "9WmGR7AZUHeM"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero inicializamos nuestro modelo usando el método *MLPClassifier*, especificando la velocidad de aprendizaje *alpha*, el tamaño de cada capa  oculta (ej. *(5,2)* significa dos capas ocultas donde la 1era posee 5 neuronas y la 2da posee 2), el método de optimización de los pesos pues existen varios (ej. descenso de gradiente estocástico - *sgd*, optimizador basado en algoritmo de Newton - *lbfgs*, optimizador por descenso de gradiente - *adam*) y *max_iter* que corresponde al número de epochs:"
      ],
      "metadata": {
        "id": "f58S_l3PUXSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Clasificador = MLPClassifier(solver='sgd',\n",
        "                    alpha=1e-5,\n",
        "                    hidden_layer_sizes=(5,2),\n",
        "                    max_iter = 300,\n",
        "                    activation ='relu')"
      ],
      "metadata": {
        "id": "XJFlR0r_UgyV"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, entrenamos el modelo de clasificación con los datos de entrenamiento (*train_data*) y sus respectivos labels (*train_labels*):"
      ],
      "metadata": {
        "id": "FWqWBicWWnbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = Clasificador.fit(train_data, train_labels)"
      ],
      "metadata": {
        "id": "0FAfwN3QUl_8"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez entrenado, revisamos el rendimiento del entrenamiento (usualmente *accuracy*):"
      ],
      "metadata": {
        "id": "hNYxkBC1XnpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Clasificador.score(train_data, train_labels)"
      ],
      "metadata": {
        "id": "BcYFMB99XldC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora evaluamos el modelo entrenado con los datos de prueba:"
      ],
      "metadata": {
        "id": "PL2cxgCyYfSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicciones  = Clasificador.predict(test_data)\n",
        "accuracy      = accuracy_score(predicciones, test_labels)\n",
        "print(\"Accuracy sobre los datos de prueba: \", accuracy)"
      ],
      "metadata": {
        "id": "Y2FwgYBeYiDh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}